(window.webpackJsonp=window.webpackJsonp||[]).push([[76],{456:function(s,t,a){"use strict";a.r(t);var n=a(42),e=Object(n.a)({},(function(){var s=this,t=s.$createElement,a=s._self._c||t;return a("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[a("h2",{attrs:{id:"arts-2019-左耳听风社群活动-每周完成一个-arts"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#arts-2019-左耳听风社群活动-每周完成一个-arts"}},[s._v("#")]),s._v(" ARTS-2019 左耳听风社群活动--每周完成一个 ARTS")]),s._v(" "),a("p",[s._v("1.Algorithm： 每周至少做一个 leetcode 的算法题\n2.Review: 阅读并点评至少一篇英文技术文章\n3.Tip: 学习至少一个技术技巧\n4.Share: 分享一篇有观点和思考的技术文章")]),s._v(" "),a("h3",{attrs:{id:"_1-algorithm"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-algorithm"}},[s._v("#")]),s._v(" 1.Algorithm:")]),s._v(" "),a("ol",{attrs:{start:"215"}},[a("li",[s._v("数组中的第K个最大元素 https://leetcode-cn.com/submissions/detail/125352531/\n剑指 Offer 40. 最小的k个数 https://leetcode-cn.com/submissions/detail/125355104/\n面试题 17.14. 最小K个数 https://leetcode-cn.com/submissions/detail/125355700/")]),s._v(" "),a("li",[s._v("二分查找 https://leetcode-cn.com/submissions/detail/125412090/")])]),s._v(" "),a("h3",{attrs:{id:"_2-review"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-review"}},[s._v("#")]),s._v(" 2.Review:")]),s._v(" "),a("p",[s._v("https://towardsdatascience.com/why-90-percent-of-all-machine-learning-models-never-make-it-into-production-ce7e250d5a4a\n为什么90%的机器学习模型从未投入生产？")]),s._v(" "),a("h4",{attrs:{id:"点评："}},[a("a",{staticClass:"header-anchor",attrs:{href:"#点评："}},[s._v("#")]),s._v(" 点评：")]),s._v(" "),a("p",[s._v("作者：Rhea Moutafis")]),s._v(" "),a("p",[s._v("当使用 Python 的 Pandas 认为尽管十分之九的科技高管认为，人工智能将成为下一次技术革命的中心，但它的采用和部署仍有增长空间。数据科学家不是罪魁祸首。")]),s._v(" "),a("p",[s._v("公司不是为机器学习而建立的：")]),s._v(" "),a("ul",[a("li",[s._v("领导的支持不仅仅是为了金钱")]),s._v(" "),a("li",[s._v("缺乏对数据的访问")]),s._v(" "),a("li",[s._v("IT、数据科学和工程之间的脱节")])]),s._v(" "),a("p",[s._v("机器学习模型有其自身的一系列挑战：")]),s._v(" "),a("ul",[a("li",[s._v("扩大规模比你想象的要难")]),s._v(" "),a("li",[s._v("劳动是重复的")]),s._v(" "),a("li",[s._v("高管们并不总是买账")]),s._v(" "),a("li",[s._v("缺乏跨语言和框架支持")]),s._v(" "),a("li",[s._v("版本控制和复现能力仍然是一个挑战")])]),s._v(" "),a("p",[s._v("总结：\n如果一个数据科学家90%的努力没有结果，那不是一个好预兆。如上所示，这不是数据科学家的错，而是由于固有的和组织上的障碍。改变并非朝夕。对于刚开始使用机器学习模型的公司来说，从一个非常小和简单的项目开始是明智的。但由于机器学习提供了许多改善客户体验和企业效率的方法，因此很明显，那些快速、早期部署模型的公司将是赢家。")]),s._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[s._v("＃通过引用仅返回x"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),s._v("的行（在其上写会更改原始df）\ndf2  "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("  df。loc "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v(" df "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'x'")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v("  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n＃通过引用仅返回x为"),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v("、"),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v("、"),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v("、"),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),s._v("或"),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),s._v("的行\ndf3  "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("  df。X。isin（范围（"),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),s._v("））\n＃通过只读引用仅返回x"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),s._v("的行（无法写入）\ndf4  "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("  df "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v(" df "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'x'")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n")])])]),a("p",[s._v("结论：\n作者在一台非常旧的 4 核 PC 上，一分钟内运行 2.5 亿行内容，觉得会在实际应用中有着举足轻重的地位。因此建议，下次处理本地或从单个 AWS 实例中处理数据集时，可以考虑使用这个框架，非常高效。")]),s._v(" "),a("h3",{attrs:{id:"_3-tip"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3-tip"}},[s._v("#")]),s._v(" 3.Tip:")]),s._v(" "),a("ol",[a("li",[s._v("Linux 关闭 GPU 进程")])]),s._v(" "),a("div",{staticClass:"language-shell extra-class"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[s._v("~"),a("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$nvidia")]),s._v("-smi\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#查看 Processes 结果")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("kill")]),s._v(" -9 PID\n")])])]),a("ol",{attrs:{start:"2"}},[a("li",[s._v("The StackOverflowError in Java")])]),s._v(" "),a("div",{staticClass:"language-shell extra-class"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[s._v("-Xss10M\n")])])]),a("ol",{attrs:{start:"3"}},[a("li",[s._v("hadoop 环境配置")])]),s._v(" "),a("div",{staticClass:"language-shell extra-class"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 环境变量配置")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("export")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token assign-left variable"}},[s._v("HADOOP_HOME")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$hadoop_home_dir")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("export")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token assign-left variable"}},[a("span",{pre:!0,attrs:{class:"token environment constant"}},[s._v("PATH")])]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token environment constant"}},[s._v("$PATH")]),a("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),a("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$HADOOP_HOME")]),s._v("/bin\n"),a("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("export")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token assign-left variable"}},[s._v("LD_LIBRARY_PATH")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$LD_LIBRARY_PATH")]),a("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),a("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$HADOOP_HOME")]),s._v("/lib/native/\n"),a("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("export")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token assign-left variable"}},[s._v("CLASSPATH")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token variable"}},[a("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")]),s._v("$HADOOP_HOME/bin/hdfs classpath --glob"),a("span",{pre:!0,attrs:{class:"token variable"}},[s._v("`")])]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("export")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token assign-left variable"}},[s._v("ARROW_LIBHDFS_DIR")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token environment constant"}},[s._v("$PATH")]),a("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),a("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$HADOOP_HOME")]),s._v("/lib/native/\n\n")])])]),a("ol",{attrs:{start:"4"}},[a("li",[s._v("hadoop 客户端命令")])]),s._v(" "),a("div",{staticClass:"language-shell extra-class"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 列出HDFS中目录的内容")]),s._v("\n$ hdfs dfs -mkdir /user\n$ hdfs dfs -mkdir /user/hduser\n$ hdfs dfs -ls /\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# put与get数据")]),s._v("\n$ hdfs dfs -put /home/hduser_/input.txt /user/hduser\n$ hdfs dfs -cat /user/hduser/input.txt\nhttps://china-testing.github.io/\n$ hdfs  dfs -get /user/hduser/input.txt /home/hduser_/test.txt\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 更多帮助可以　hdfs dfs -usage <option> 或　hdfs dfs -help <option>")]),s._v("\n")])])]),a("ol",{attrs:{start:"5"}},[a("li",[s._v("python 操作 hadoop")])]),s._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# pyarrow")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" pyarrow "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" pa\nfs "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" pa"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("hdfs"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("connect"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("host"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" port"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" user"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("user"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" kerb_ticket"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("ticket_cache_path"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("with")]),s._v(" fs"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("open")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("path"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'rb'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" f"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n\nfs "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" pa"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("hdfs"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("connect"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("host"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" port"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" user"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("user"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" kerb_ticket"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("ticket_cache_path"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n                    driver"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'libhdfs3'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# hdfs")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" hdfs "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" InsecureClient\nclient "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" InsecureClient"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'http://localhost:50070'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" user"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'hduser_'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\nfs_folders_list "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" client"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("list")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"/"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("fs_folders_list"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("with")]),s._v(" client"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("read"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'/user/hduser/input.txt'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" encoding"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'utf-8'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" reader"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" line "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" reader"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("line"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])])]),a("h3",{attrs:{id:"_4-share"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_4-share"}},[s._v("#")]),s._v(" 4.Share:")]),s._v(" "),a("p",[s._v("https://blog.csdn.net/u010738528/article/details/105276504\nwin10 单机配置 hadoop 3.1.1")]),s._v(" "),a("p",[s._v("https://blog.csdn.net/qq_26295547/article/details/79721488\nhadoop学习笔记1-客户端搭建")])])}),[],!1,null,null,null);t.default=e.exports}}]);