(window.webpackJsonp=window.webpackJsonp||[]).push([[45],{426:function(s,t,a){"use strict";a.r(t);var n=a(42),r=Object(n.a)({},(function(){var s=this,t=s.$createElement,a=s._self._c||t;return a("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[a("h2",{attrs:{id:"arts-2019-左耳听风社群活动-每周完成一个-arts"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#arts-2019-左耳听风社群活动-每周完成一个-arts"}},[s._v("#")]),s._v(" ARTS-2019 左耳听风社群活动--每周完成一个 ARTS")]),s._v(" "),a("p",[s._v("1.Algorithm： 每周至少做一个 leetcode 的算法题\n2.Review: 阅读并点评至少一篇英文技术文章\n3.Tip: 学习至少一个技术技巧\n4.Share: 分享一篇有观点和思考的技术文章")]),s._v(" "),a("h3",{attrs:{id:"_1-algorithm"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-algorithm"}},[s._v("#")]),s._v(" 1.Algorithm:")]),s._v(" "),a("p",[s._v("Search a 2D Matrix https://leetcode.com/submissions/detail/327030583/")]),s._v(" "),a("h3",{attrs:{id:"_2-review"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-review"}},[s._v("#")]),s._v(" 2.Review:")]),s._v(" "),a("p",[s._v("https://python-history.blogspot.com/2018/05/the-origins-of-pgen.html")]),s._v(" "),a("h4",{attrs:{id:"点评："}},[a("a",{staticClass:"header-anchor",attrs:{href:"#点评："}},[s._v("#")]),s._v(" 点评：")]),s._v(" "),a("p",[s._v("Guido van Rossum 在本文中，介绍了 pgen 的起源。")]),s._v(" "),a("p",[s._v("Pgen 有两个版本一个是最初的，用 C 语言写的，还有一个则是用 Python 重写的，在 lib2to3/pgen2 下面，创建 pgen 的原因：\n1.词法解析作者尝试过 Lex 但在尝试扫描超 255 个字节的标记符时 Lex 版本会发生段错误，而语法分析生成器基本上只有 Yacc 但是出于某些原因，作者并不喜欢它。\n2.网页所称的的左分解（将 A -> X | X Y Z 替换成 A -> X B; B -> Y Z | "),a("empty",[s._v("），作者会重写成 A -> X [Y Z]，通过“正则表达式 -> NFA -> DFA”的转换过程，解析引擎（该网页中前面的 syntacticAnalysis 函数）依然可以工作在由这些规则所派生的解析表上。\n3.解析引擎生成的解析树节点可能有很多子节点，例如，对于上面的规则 A -> X [Y Z]，节点 A 可能有 1 个子节点（X）或者 3 个（X Y Z）。代码生成器中就需要有一个简单的检查，来确定它遇到的是哪一种可能的情况。（这已经被证明是一把双刃剑，后来作者添加了一个由单独的生成器所驱动的“解析树 -> AST”步骤，以简化字节码生成器。）\n4.由于作者本身熟悉 LL(1) 解析器，并已认真地编写过一些递归下降的 LL(1) 解析器——作者很喜欢它，而且还熟悉 LL(1) 解析器的生成技术（同样是因为龙书），所以有了一个改进念头想要试验下：使用正则表达式（某种程度的）而不是标准的 BNF 格式。龙书还教会了作者如何将正则表达式转换成 DFA，所以作者把所有这些东西一结合，pgen 就诞生了。")])],1),s._v(" "),a("p",[s._v("Pgen2 创建的原因：作者在 Google 一项设计定制语言的任务（目标是作关于系统配置的安全性判定）。作者决定设计一些稍微像 Python 的东西，用 Python 来实现，并且决定要重用 pgen，但是后端要基于 Python，使用 tokenize.py 作为词法分析器。所以作者用 Python 重写了 pgen 里的那些算法，然后继续构建了剩余的部分。")]),s._v(" "),a("p",[s._v("结束语：如果让作者重做一遍，作者可能会选择一个更强大的解析引擎，可能是 LALR(1) 的某个版本（例如 Yacc/Bison）。LALR(1) 的某些地方要比 LL(1) 更给力，也更加有用，例如，关键字参数。")]),s._v(" "),a("p",[s._v("备注：\n1.龙书，原文是 Dragon book，指代《Compilers: Principles, Techniques, and Tools》，这是一本讲编译原理的书，属于编译原理界的殿堂级存在。\n2.Lex 是“LEXical compiler”的简称，用来生成词法分析器；Yacc 是“Yet another compiler compiler”的简称，用来生成语法分析器。\n3.段错误，原文是 segfault，全称是segmentation fault，指的是因为越界访问内存空间而导致的报错。")]),s._v(" "),a("h3",{attrs:{id:"_3-tip"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3-tip"}},[s._v("#")]),s._v(" 3.Tip:")]),s._v(" "),a("ol",[a("li",[s._v("编写带括号的四则运算产生式")])]),s._v(" "),a("div",{staticClass:"language-java extra-class"},[a("pre",{pre:!0,attrs:{class:"language-java"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 例子：2*(1+2)||2  测试地址 https://pegjs.org/online")]),s._v("\nstart\n  "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("LogicalExpression")]),s._v("\n\n"),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("DecimalNumber")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"DecimalNumber"')]),s._v("\n  "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" digits"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("9")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("parseInt")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("digits"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("join")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('""')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n  \n"),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("PrimaryExpression")]),s._v("\n  "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("DecimalNumber")]),s._v("\n  "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"("')]),s._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("AdditiveExpression")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("AdditiveExpression")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('")"')]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("AdditiveExpression")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\n"),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("MultiplicativeExpression")]),s._v("\n  "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" left"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("PrimaryExpression")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"*"')]),s._v(" right"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("MultiplicativeExpression")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" left "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" right"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n  "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v(" left"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("PrimaryExpression")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"/"')]),s._v(" right"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("MultiplicativeExpression")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" left "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v(" right"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n  "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("PrimaryExpression")]),s._v("\n\n"),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("AdditiveExpression")]),s._v("\n  "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" left"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("MultiplicativeExpression")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"+"')]),s._v(" right"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("AdditiveExpression")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" left "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" right"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n  "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v(" left"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("MultiplicativeExpression")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"-"')]),s._v(" right"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("AdditiveExpression")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" left "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" right"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n  "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("MultiplicativeExpression")]),s._v("\n\n"),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("LogicalExpression")]),s._v("\n  "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" left"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("AdditiveExpression")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"||"')]),s._v(" right"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("LogicalExpression")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" left "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("||")]),s._v(" right"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n  "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v(" left"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("AdditiveExpression")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"&&"')]),s._v(" right"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("LogicalExpression")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" left "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("&&")]),s._v(" right"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n  "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("AdditiveExpression")]),s._v("\n")])])]),a("ol",{attrs:{start:"2"}},[a("li",[s._v("乔姆斯基 (chomsky) 文法分类")])]),s._v(" "),a("p",[s._v("非形式语言\n中文，英文\n形式语言（乔姆斯基谱系）\n0型 无限制文法\n1型 上下文相关文法\n2型 上下文无关文法\n3型 正则文法")]),s._v(" "),a("p",[s._v("0型文法其中,至少含有一个非终结符，并且，表示终结符和非终结符的并集。\n1型文法：又称为上下文有关文法，对任一产生式α→β，都有|β|≥|α|， 仅仅 S→ε除外\n（1）：式子左边可以有多个字符，但必须有一个非终结符\n（2）：式子右边可以有多个字符，可以是终结符，也可以是非终结符，但必须是有限个字符\n（3）：左边长度必须小于右边（例外）\n2型文法：又称为上下文无关文法，对任一产生式α→β，都有α∈VN ， β∈(VN∪VT)*\n（1）：式子左边只能有一个字符，而且必须是非终结符\n（2）：式子右边可以有多个字符，可以是终结符，也可以是非终结符，8但必须是有限个字符\n3型文法：又称为正规文法（正规文法又包括左线性文法和右线性文法）\n（1）：式子左边只能有一个字符，而且必须是非终结符\n（2）：式子右边最多有二个字符，而且如果有二个字符必须是一个终结符和一个非终结符\n如果只有一个字符，那么必须是终结符\n（3）：式子右边的格式一定要一致，也就是说如果有一个是（终结符+非终结符）那么所有的式子都必须是（终结符+非终结符）\n  如果有一个是（非终结符+终结符），那么所有的式子都必须是（非终结符+终结符）\n正规文法——左线性文法：\n（1）：必须是三型文法\n（2）：式子右边的产生是（非终结符+终结符）的格式\n正规文法——右线型文法：\n（1）：必须是三型文法\n（2）：式子右边的产生式是（终结符+非终结符）的格式")]),s._v(" "),a("ol",{attrs:{start:"3"}},[a("li",[s._v("计算机语言分类(待更正)\n1型文法 JavaScript Python\n2型文法 C、Pascal、Java、C#、C++、PHP、0C、 Swift、Go、Scala、R\n3型文法 正则表达式 SQL")])]),s._v(" "),a("h3",{attrs:{id:"_4-share"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_4-share"}},[s._v("#")]),s._v(" 4.Share:")]),s._v(" "),a("p",[s._v("less开发常用知识点归纳\nhttps://www.jianshu.com/p/d81496ed0e29")])])}),[],!1,null,null,null);t.default=r.exports}}]);